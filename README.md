# Jigsaw Puzzles: Splitting Harmful Questions to Jailbreak Large Language Models
The repo is for paper [Jigsaw Puzzles: Splitting Harmful Questions to Jailbreak Large Language Models](https://arxiv.org/abs/2410.11459)
## Citation
```
@article{yang2024jigsaw,
  title={Jigsaw Puzzles: Splitting Harmful Questions to Jailbreak Large Language Models},
  author={Yang, Hao and Qu, Lizhen and Shareghi, Ehsan and Haffari, Gholamreza},
  journal={arXiv preprint arXiv:2410.11459},
  year={2024}
}
```
